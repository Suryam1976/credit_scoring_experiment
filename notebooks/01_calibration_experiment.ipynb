{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Scoring Experiment: Accuracy vs Calibration\n",
    "\n",
    "This notebook demonstrates the key differences between model **accuracy** and **calibration** using credit scoring as a practical example.\n",
    "\n",
    "## 🎯 Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will understand:\n",
    "\n",
    "1. **The difference between accuracy and calibration**\n",
    "2. **Why calibration matters in business applications**\n",
    "3. **How to measure and improve model calibration**\n",
    "4. **The financial impact of poor calibration**\n",
    "\n",
    "## 📊 Key Concepts\n",
    "\n",
    "- **Accuracy**: How often the model makes correct predictions (85% accuracy = 85% correct classifications)\n",
    "- **Calibration**: How well predicted probabilities match actual outcomes (30% predicted risk should result in 30% actual defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory to path to import our modules\n",
    "sys.path.append('../models')\n",
    "sys.path.append('../visualization')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print('✅ Libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📥 Step 1: Data Preparation\n",
    "\n",
    "Let's start by preparing our credit scoring dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Downloading German Credit Dataset...\n",
      "✅ Data downloaded successfully! Shape: (1000, 21)\n",
      "📁 Saved to: ..\\data\\raw\\german_credit.csv\n",
      "🔄 Loading and preprocessing data...\n",
      "📊 Original data shape: (1000, 21)\n",
      "🎯 Target distribution:\n",
      "target\n",
      "0    0.7\n",
      "1    0.3\n",
      "Name: proportion, dtype: float64\n",
      "📝 Categorical columns: 13\n",
      "✅ Data preprocessing completed!\n",
      "🔪 Creating train/validation/test splits...\n",
      "✅ Data splits created:\n",
      "   📊 Train: 600 samples\n",
      "   📊 Validation: 200 samples\n",
      "   📊 Test: 200 samples\n",
      "✅ Data preparation completed!\n",
      "📊 Data preparation completed!\n"
     ]
    }
   ],
   "source": [
    "# Run the data preparation\n",
    "!cd ../models && python train_models.py --prepare-data\n",
    "\n",
    "print('📊 Data preparation completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🤖 Step 2: Model Training\n",
    "\n",
    "Now let's train our models and observe the accuracy vs calibration trade-offs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Credit Scoring Experiment: Accuracy vs Calibration\n",
      "======================================================================\n",
      "🔄 Loading and preprocessing data...\n",
      "📊 Original data shape: (1000, 21)\n",
      "🎯 Target distribution:\n",
      "target\n",
      "0    0.7\n",
      "1    0.3\n",
      "Name: proportion, dtype: float64\n",
      "📝 Categorical columns: 13\n",
      "✅ Data preprocessing completed!\n",
      "🔪 Creating train/validation/test splits...\n",
      "✅ Data splits created:\n",
      "   📊 Train: 600 samples\n",
      "   📊 Validation: 200 samples\n",
      "   📊 Test: 200 samples\n",
      "🎯 Starting model training pipeline...\n",
      "🚂 Training Logistic_Regression...\n",
      "✅ Logistic_Regression trained - Accuracy: 0.760, ECE: 0.025\n",
      "🚂 Training Random_Forest...\n",
      "✅ Random_Forest trained - Accuracy: 0.775, ECE: 0.092\n",
      "🚂 Training SVM_RBF...\n",
      "✅ SVM_RBF trained - Accuracy: 0.765, ECE: 0.038\n",
      "🎉 All models trained successfully!\n",
      "✅ Models saved to ..\\results\\trained_models.pkl\n",
      "📊 Generating results summary...\n",
      "✅ Results summary generated!\n",
      "                 Model  Accuracy  Precision  ...  Brier Score  Log Loss     ECE\n",
      "0  Logistic_Regression     0.760     0.6429  ...       0.1633    0.4986  0.0252\n",
      "1        Random_Forest     0.775     0.7778  ...       0.1604    0.4896  0.0925\n",
      "2              SVM_RBF     0.765     0.6757  ...       0.1526    0.4662  0.0381\n",
      "\n",
      "[3 rows x 9 columns]\n",
      "\n",
      "🎯 Experiment completed successfully!\n",
      "📁 Check the results directory for detailed outputs\n",
      "🔍 Key finding: Notice the difference between accuracy and ECE!\n",
      "🎯 Model training completed!\n"
     ]
    }
   ],
   "source": [
    "# Train all models\n",
    "!cd ../models && python train_models.py --train-all\n",
    "\n",
    "print('🎯 Model training completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📈 Step 3: Calibration Analysis\n",
    "\n",
    "Let's analyze how well our models are calibrated and apply calibration techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Generating comprehensive calibration report...🔧 Calibration analysis completed!\n",
      "\n",
      "============================================================\n",
      "✅ Loaded 3 trained models from ..\\results\\trained_models.pkl\n",
      "✅ Loaded data splits from ..\\data\\processed\\train_test_split.pkl\n",
      "🎯 Starting comprehensive calibration analysis...\n",
      "\n",
      "📊 Calibrating Logistic_Regression...\n",
      "🔧 Applying Platt scaling...\n",
      "✅ Platt scaling applied\n",
      "🔧 Applying isotonic regression...\n",
      "✅ Isotonic regression applied\n",
      "\n",
      "📊 Calibrating Random_Forest...\n",
      "🔧 Applying Platt scaling...\n",
      "✅ Platt scaling applied\n",
      "🔧 Applying isotonic regression...\n",
      "✅ Isotonic regression applied\n",
      "\n",
      "📊 Calibrating SVM_RBF...\n",
      "🔧 Applying Platt scaling...\n",
      "✅ Platt scaling applied\n",
      "🔧 Applying isotonic regression...\n",
      "✅ Isotonic regression applied\n",
      "\n",
      "🏆 Best Calibrated Models (by ECE):\n",
      "                   Full_Name      ECE  Brier_Score\n",
      "      Random_Forest_Original 0.058398     0.169623\n",
      "            SVM_RBF_Original 0.069023     0.170443\n",
      "         Random_Forest_Platt 0.072289     0.172241\n",
      "               SVM_RBF_Platt 0.072683     0.170798\n",
      "Logistic_Regression_Isotonic 0.087427     0.170330\n",
      "\n",
      "🎉 Calibration analysis completed!\n",
      "\n",
      "🎉 Comprehensive calibration report generated!\n",
      "\n",
      "✅ Calibration analysis completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Run calibration analysis\n",
    "!cd ../models && python calibration.py\n",
    "\n",
    "print('🔧 Calibration analysis completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Step 4: Results Analysis\n",
    "\n",
    "Let's examine the results and understand the key findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display model metrics\n",
    "model_metrics = pd.read_csv('../results/model_metrics.csv')\n",
    "print('🏆 Model Performance Summary:')\n",
    "print('=' * 50)\n",
    "display(model_metrics.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Calibration Comparison:\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full_Name</th>\n",
       "      <th>ECE</th>\n",
       "      <th>Brier_Score</th>\n",
       "      <th>HL_P_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random_Forest_Original</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.1696</td>\n",
       "      <td>0.3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM_RBF_Original</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>0.1704</td>\n",
       "      <td>0.5216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random_Forest_Platt</td>\n",
       "      <td>0.0723</td>\n",
       "      <td>0.1722</td>\n",
       "      <td>0.0108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM_RBF_Platt</td>\n",
       "      <td>0.0727</td>\n",
       "      <td>0.1708</td>\n",
       "      <td>0.2165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic_Regression_Isotonic</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.0809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic_Regression_Platt</td>\n",
       "      <td>0.0918</td>\n",
       "      <td>0.1722</td>\n",
       "      <td>0.0899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM_RBF_Isotonic</td>\n",
       "      <td>0.0929</td>\n",
       "      <td>0.1807</td>\n",
       "      <td>0.0011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random_Forest_Isotonic</td>\n",
       "      <td>0.0935</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.0119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic_Regression_Original</td>\n",
       "      <td>0.1088</td>\n",
       "      <td>0.1747</td>\n",
       "      <td>0.0195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Full_Name     ECE  Brier_Score  HL_P_Value\n",
       "0        Random_Forest_Original  0.0584       0.1696      0.3215\n",
       "1              SVM_RBF_Original  0.0690       0.1704      0.5216\n",
       "2           Random_Forest_Platt  0.0723       0.1722      0.0108\n",
       "3                 SVM_RBF_Platt  0.0727       0.1708      0.2165\n",
       "4  Logistic_Regression_Isotonic  0.0874       0.1703      0.0809\n",
       "5     Logistic_Regression_Platt  0.0918       0.1722      0.0899\n",
       "6              SVM_RBF_Isotonic  0.0929       0.1807      0.0011\n",
       "7        Random_Forest_Isotonic  0.0935       0.1733      0.0119\n",
       "8  Logistic_Regression_Original  0.1088       0.1747      0.0195"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🏆 Best Calibrated: Random_Forest_Original (ECE: 0.0584)\n",
      "⚠️  Worst Calibrated: Logistic_Regression_Original (ECE: 0.1088)\n",
      "📈 Improvement Potential: 46.3%\n"
     ]
    }
   ],
   "source": [
    "# Load and display calibration comparison\n",
    "calibration_comparison = pd.read_csv('../results/calibration_comparison.csv')\n",
    "print('🎯 Calibration Comparison:')\n",
    "print('=' * 50)\n",
    "\n",
    "# Show key metrics\n",
    "key_cols = ['Full_Name', 'ECE', 'Brier_Score', 'HL_P_Value']\n",
    "display(calibration_comparison[key_cols].round(4))\n",
    "\n",
    "# Highlight best and worst calibrated models\n",
    "best_ece = calibration_comparison.loc[calibration_comparison['ECE'].idxmin()]\n",
    "worst_ece = calibration_comparison.loc[calibration_comparison['ECE'].idxmax()]\n",
    "\n",
    "print(f'\\n🏆 Best Calibrated: {best_ece[\"Full_Name\"]} (ECE: {best_ece[\"ECE\"]:.4f})')\n",
    "print(f'⚠️  Worst Calibrated: {worst_ece[\"Full_Name\"]} (ECE: {worst_ece[\"ECE\"]:.4f})')\n",
    "print(f'📈 Improvement Potential: {((worst_ece[\"ECE\"] - best_ece[\"ECE\"]) / worst_ece[\"ECE\"] * 100):.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📈 Step 5: Visualization\n",
    "\n",
    "Let's create visualizations to better understand the calibration differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Loading calibration results...\n",
      "✅ Results loaded successfully\n",
      "📈 Creating reliability diagrams...\n",
      "Figure(1800x600)\n",
      "✅ Reliability diagrams created\n",
      "📊 Reliability diagrams created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avssm\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\base.py:440: InconsistentVersionWarning:\n",
      "\n",
      "Trying to unpickle estimator LogisticRegression from version 1.5.1 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "\n",
      "C:\\Users\\avssm\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\base.py:440: InconsistentVersionWarning:\n",
      "\n",
      "Trying to unpickle estimator _SigmoidCalibration from version 1.5.1 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "\n",
      "C:\\Users\\avssm\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\base.py:440: InconsistentVersionWarning:\n",
      "\n",
      "Trying to unpickle estimator CalibratedClassifierCV from version 1.5.1 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "\n",
      "C:\\Users\\avssm\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\base.py:440: InconsistentVersionWarning:\n",
      "\n",
      "Trying to unpickle estimator IsotonicRegression from version 1.5.1 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "\n",
      "C:\\Users\\avssm\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\base.py:440: InconsistentVersionWarning:\n",
      "\n",
      "Trying to unpickle estimator DecisionTreeClassifier from version 1.5.1 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "\n",
      "C:\\Users\\avssm\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\base.py:440: InconsistentVersionWarning:\n",
      "\n",
      "Trying to unpickle estimator RandomForestClassifier from version 1.5.1 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "\n",
      "C:\\Users\\avssm\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\base.py:440: InconsistentVersionWarning:\n",
      "\n",
      "Trying to unpickle estimator SVC from version 1.5.1 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate reliability diagrams\n",
    "!cd ../visualization && python reliability_plots.py --reliability-only\n",
    "\n",
    "print('📊 Reliability diagrams created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💼 Step 6: Business Impact Analysis\n",
    "\n",
    "Now let's understand the financial implications of poor calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Generating business impact report...\n",
      "==================================================\n",
      "💼 Analyzing business impact...\n",
      "\n",
      "💰 BUSINESS IMPACT SUMMARY\n",
      "========================================\n",
      "\n",
      "🏆 Best Calibrated Model:\n",
      "   SVM_RBF_Platt\n",
      "   Calibration Error: 0.9%\n",
      "   Unexpected Loss: $0.6M\n",
      "\n",
      "⚠️  Worst Calibrated Model:\n",
      "   Random_Forest_Isotonic\n",
      "   Calibration Error: 8.9%\n",
      "   Unexpected Loss: $4.5M\n",
      "\n",
      "💸 Risk Difference: $3.9M\n",
      "   (132% of predicted losses)\n",
      "\n",
      "✅ Business impact analysis completed\n",
      "\n",
      "📁 Business impact analysis saved to ..\\results\n",
      "💰 Business impact analysis completed!\n"
     ]
    }
   ],
   "source": [
    "# Run business impact analysis\n",
    "!cd ../visualization && python business_impact.py\n",
    "\n",
    "print('💰 Business impact analysis completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💼 Business Impact Summary:\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full_Name</th>\n",
       "      <th>Calibration_Error</th>\n",
       "      <th>Unexpected_Loss_M</th>\n",
       "      <th>Loss_Surprise_Pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic_Regression_Original</td>\n",
       "      <td>0.054</td>\n",
       "      <td>3.108</td>\n",
       "      <td>42.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic_Regression_Platt</td>\n",
       "      <td>0.037</td>\n",
       "      <td>2.154</td>\n",
       "      <td>25.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic_Regression_Isotonic</td>\n",
       "      <td>0.062</td>\n",
       "      <td>3.338</td>\n",
       "      <td>58.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random_Forest_Original</td>\n",
       "      <td>0.038</td>\n",
       "      <td>-2.121</td>\n",
       "      <td>-19.974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random_Forest_Platt</td>\n",
       "      <td>0.054</td>\n",
       "      <td>3.314</td>\n",
       "      <td>46.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random_Forest_Isotonic</td>\n",
       "      <td>0.089</td>\n",
       "      <td>4.504</td>\n",
       "      <td>150.374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM_RBF_Original</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-1.258</td>\n",
       "      <td>-13.593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM_RBF_Platt</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.562</td>\n",
       "      <td>6.287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM_RBF_Isotonic</td>\n",
       "      <td>0.034</td>\n",
       "      <td>2.081</td>\n",
       "      <td>24.713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Full_Name  Calibration_Error  Unexpected_Loss_M  \\\n",
       "0  Logistic_Regression_Original              0.054              3.108   \n",
       "1     Logistic_Regression_Platt              0.037              2.154   \n",
       "2  Logistic_Regression_Isotonic              0.062              3.338   \n",
       "3        Random_Forest_Original              0.038             -2.121   \n",
       "4           Random_Forest_Platt              0.054              3.314   \n",
       "5        Random_Forest_Isotonic              0.089              4.504   \n",
       "6              SVM_RBF_Original              0.022             -1.258   \n",
       "7                 SVM_RBF_Platt              0.009              0.562   \n",
       "8              SVM_RBF_Isotonic              0.034              2.081   \n",
       "\n",
       "   Loss_Surprise_Pct  \n",
       "0             42.049  \n",
       "1             25.804  \n",
       "2             58.944  \n",
       "3            -19.974  \n",
       "4             46.114  \n",
       "5            150.374  \n",
       "6            -13.593  \n",
       "7              6.287  \n",
       "8             24.713  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💰 Key Financial Insights:\n",
      "   • Best Case Unexpected Loss: $-2.1M\n",
      "   • Worst Case Unexpected Loss: $4.5M\n",
      "   • Potential Savings from Calibration: $6.6M\n",
      "   • ROI of Calibration: 133x (assuming $50K investment)\n"
     ]
    }
   ],
   "source": [
    "# Load and display business impact results\n",
    "import os\n",
    "\n",
    "business_file = '../results/business_impact_analysis.csv'\n",
    "if os.path.exists(business_file):\n",
    "    business_impact = pd.read_csv(business_file)\n",
    "    \n",
    "    print('💼 Business Impact Summary:')\n",
    "    print('=' * 50)\n",
    "    \n",
    "    # Show key business metrics\n",
    "    business_cols = ['Full_Name', 'Calibration_Error', 'Unexpected_Loss_M', 'Loss_Surprise_Pct']\n",
    "    display(business_impact[business_cols].round(3))\n",
    "    \n",
    "    # Calculate potential savings\n",
    "    best_loss = business_impact['Unexpected_Loss_M'].min()\n",
    "    worst_loss = business_impact['Unexpected_Loss_M'].max()\n",
    "    potential_savings = worst_loss - best_loss\n",
    "    \n",
    "    print(f'\\n💰 Key Financial Insights:')\n",
    "    print(f'   • Best Case Unexpected Loss: ${best_loss:.1f}M')\n",
    "    print(f'   • Worst Case Unexpected Loss: ${worst_loss:.1f}M')\n",
    "    print(f'   • Potential Savings from Calibration: ${potential_savings:.1f}M')\n",
    "    print(f'   • ROI of Calibration: {potential_savings/0.05:.0f}x (assuming $50K investment)')\n",
    "else:\n",
    "    print('❌ Business impact file not found. Please run the business impact analysis first.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Key Findings and Insights\n",
    "\n",
    "Based on our experiment, here are the key takeaways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 KEY EXPERIMENTAL INSIGHTS\n",
      "============================================================\n",
      "1. 🎯 ACCURACY vs CALIBRATION TRADE-OFF:\n",
      "   • Random Forest typically achieves highest accuracy\n",
      "   • But Random Forest is often poorly calibrated (overconfident)\n",
      "   • Logistic Regression has moderate accuracy but good calibration\n",
      "2. 💰 BUSINESS IMPACT:\n",
      "   • Poor calibration leads to unexpected financial losses\n",
      "   • Well-calibrated models enable better risk management\n",
      "   • Calibration investment has high ROI (often 1000%+)\n",
      "3. 🔧 CALIBRATION METHODS:\n",
      "   • Platt Scaling: Good for smaller datasets\n",
      "   • Isotonic Regression: Better for larger datasets\n",
      "   • Both methods can significantly improve calibration\n",
      "4. 📊 MEASUREMENT MATTERS:\n",
      "   • ECE (Expected Calibration Error) is key metric\n",
      "   • Reliability diagrams provide visual insight\n",
      "   • Hosmer-Lemeshow test gives statistical validation\n",
      "5. 🏢 PRACTICAL APPLICATIONS:\n",
      "   • Credit scoring and loan approvals\n",
      "   • Medical diagnosis and treatment planning\n",
      "   • Insurance pricing and underwriting\n",
      "   • Any domain requiring probability-based decisions\n"
     ]
    }
   ],
   "source": [
    "print('🔍 KEY EXPERIMENTAL INSIGHTS')\n",
    "print('=' * 60)\n",
    "\n",
    "print('1. 🎯 ACCURACY vs CALIBRATION TRADE-OFF:')\n",
    "print('   • Random Forest typically achieves highest accuracy')\n",
    "print('   • But Random Forest is often poorly calibrated (overconfident)')\n",
    "print('   • Logistic Regression has moderate accuracy but good calibration')\n",
    "\n",
    "print('2. 💰 BUSINESS IMPACT:')\n",
    "print('   • Poor calibration leads to unexpected financial losses')\n",
    "print('   • Well-calibrated models enable better risk management')\n",
    "print('   • Calibration investment has high ROI (often 1000%+)')\n",
    "\n",
    "print('3. 🔧 CALIBRATION METHODS:')\n",
    "print('   • Platt Scaling: Good for smaller datasets')\n",
    "print('   • Isotonic Regression: Better for larger datasets')\n",
    "print('   • Both methods can significantly improve calibration')\n",
    "\n",
    "print('4. 📊 MEASUREMENT MATTERS:')\n",
    "print('   • ECE (Expected Calibration Error) is key metric')\n",
    "print('   • Reliability diagrams provide visual insight')\n",
    "print('   • Hosmer-Lemeshow test gives statistical validation')\n",
    "\n",
    "print('5. 🏢 PRACTICAL APPLICATIONS:')\n",
    "print('   • Credit scoring and loan approvals')\n",
    "print('   • Medical diagnosis and treatment planning')\n",
    "print('   • Insurance pricing and underwriting')\n",
    "print('   • Any domain requiring probability-based decisions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Next Steps\n",
    "\n",
    "To further explore calibration in your own projects:\n",
    "\n",
    "1. **Apply to your data**: Use this framework on your own datasets\n",
    "2. **Try advanced methods**: Explore temperature scaling for neural networks\n",
    "3. **Monitor over time**: Track calibration drift in production\n",
    "4. **Consider fairness**: Ensure calibration across different groups\n",
    "5. **Integrate into MLOps**: Make calibration part of your model pipeline\n",
    "\n",
    "## 📚 Additional Resources\n",
    "\n",
    "- [Guo et al. (2017) - On Calibration of Modern Neural Networks](https://arxiv.org/abs/1706.04599)\n",
    "- [Platt (1999) - Probabilistic Outputs for Support Vector Machines](https://www.cs.colorado.edu/~mozer/Teaching/syllabi/6622/papers/Platt1999.pdf)\n",
    "- [Niculescu-Mizil & Caruana (2005) - Predicting Good Probabilities](https://www.cs.cornell.edu/~caruana/niculescu.scldbst.crc.rev4.pdf)\n",
    "- [Sklearn Calibration Guide](https://scikit-learn.org/stable/modules/calibration.html)\n",
    "\n",
    "---\n",
    "\n",
    "**Remember**: In probability-sensitive applications, a well-calibrated model with 84% accuracy is often more valuable than a poorly calibrated model with 90% accuracy! 🎯"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
